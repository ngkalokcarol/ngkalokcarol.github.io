# Carol Ng
Loves all things Data. Let's talk about Data Science.

*â€œIf you can't measure it, you can't manage it."*
<br>
# Education
* Masters of Science (Business Analytics), *University of Minnesota*
* Bachelors of Arts (Business Enterprise), *University of Birmingham*
* Incomplete: Bachelors of Science (Computer Science), *Hong Kong Baptist University (Attended 2 of 3 years)*
<br>

# Data Science Projects

## Machine Learning

#### [ Spam Emails detection](https://github.com/ngkalokcarol/spam_email_detection)

Supervised Machine Learning with dataset labelled as Spam (Class 1) and Non-Spam (Class 0). Built a classification model to predict and classify emails that are potentially Spam.  

<i> Tools: pandas, numpy, matplotlib, sklearn, xgboost</i>

#### [ Marketing Campaign Optimization](https://github.com/ngkalokcarol/Marketing_Campaign_optimization)

Supervised Machine Learning with dataset labelled as 'Yes' and 'No' regarding whether customers bought a Term Deposit after the Direct Marketing Call. In this project Exploratory Data Analysis is conducted to identify the patterns and a classification model is built to optimize sales call activity to develop future strategies with the goal to achieve a greater effectivenesss of future marketing calls. 

<i> Tools: pandas, numpy, matplotlib, seaborn, sklearn, xgboost</i>

#### [ Santander Customer Transaction Prediction](https://github.com/ngkalokcarol/santander_customer_transaction_prediction)

Supervised Machine Learning with dataset labelled as Customers Made Transaction (Class 1) and Customers Did Not Make Transaction (Class 0) in the bank. We dealt with class highly imbalance issue, feature engineering (Data UpSampling and Stratified K Fold) and compared various models - Logistic Regression, Random Forest, XGBoost and LightGBM and evaulated why LightGBM is chosen. 

<i> Tools: pandas, numpy, matplotlib, sklearn, xgboost, tensorflow, lightgbm, spicy, skopt, bayes_opt</i>

## Natural Language Processing

#### [ NLP IMDB review classification](https://github.com/ngkalokcarol/NLP-IMDB-review-classification)

Analyzed the IMDB Reviews Dataset with 50k movie reviews in text format, used transformer for text preprocessing, BERT as Classifier and Tokenizer along with the input modules to classify the sentiment of the review (Positive or Negative). 

<i> Tools: transformers, tensorflow, pandas, shutil </i>

## Big Data Architecture, Data Analysis and Visualisation

#### [ AWS S3, Redshift, Quicksight, Lambda Dashboard - Iowa Liquor Sales](https://github.com/ngkalokcarol/AWS_S3_Redshift_Lambda_Quicksight_Dashboard_IowaLiquorSales)

Our project seeks to showcase the ease of ingesting big data into AWS S3, creating materialized views and exploring data quickly using AWS RedShift, visualizing meaningful dashboards to drive business insights through AWS QuickSight, and automatically sharing reports with teammates via AWS Lambda and AWS SES - Simple Email Service. Combined, our project shows a full data analytics pipeline capable of managing very large amounts of data with exceptional performance at a fraction of the cost of alternative tools. Our project would be suitable for any oraganization that needs to analyze and visualize large amounts of structured and unstructured data quickly.


![ezgif com-gif-maker (1)](https://user-images.githubusercontent.com/50436546/167037001-8a695d04-699c-40de-9fff-1a26b1d93f9d.gif)

<img width="870" alt="image" src="https://user-images.githubusercontent.com/50436546/204318004-b445bd8b-2d43-4d04-8fe6-d129294d82d1.png">

<i> Tools: AWS S3, Redshift, QuickSight, Lambda, SES </i>

## Deep Learning or Neural Network

#### [ Dogs or Cats Image Classification](https://github.com/ngkalokcarol/Dogs_or_Cats_image_classification)

Image Classification exercise on Kaggle. Used CNN and Transfer Learning to train the model and classify 25k images of cats and dogs.

<i> Tools: Numpy, Pandas, matplotlib, seaborn, sklearn, tensorflow, keras </i>

#### [ Shallow or Deep Neural Network](https://github.com/ngkalokcarol/Shallow_VS_Deep_NeuralNetwork)

Train 3 versions of Neural Network, with different numbers of hidden layer (NN with 1 hidden layer, 2 hidden layers and 3 hidden layers), using Mean squared error as objective function and error measurement as evaulation metrics to compare the model with 1, 2 or 3 hidden layers. 

<i> Tools: Numpy, Pandas, math, tensorflow, keras </i>

## Reinforcement Learning

#### [ Cost Aware A/B Testing](https://github.com/ngkalokcarol/Cost-Aware_A-B-Testing)

Formulated an A/B Testing Experiment into specific Reinforcement Learning problem and compared different strategies performance. 

<i> Tools: Numpy, Pandas, Matplotlib, Greedy Approach with optimistic initialization, Epsilon-Greedy strategy, Upper-Confidence-Bound (UCB) Strategy </i>
